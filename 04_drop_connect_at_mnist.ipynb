{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]    = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "from random import randint\n",
    "import time\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from   keras.datasets   import mnist\n",
    "\n",
    "from   tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "eps = 1e-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to 1 dim\n",
    "X_train      = X_train.reshape(np.shape(X_train)[0], \n",
    "                               (np.shape(X_train)[1] * np.shape(X_train)[2]))\n",
    "X_test       = X_test.reshape(np.shape(X_test)[0], \n",
    "                              (np.shape(X_test)[1] * np.shape(X_test)[2]))\n",
    "\n",
    "# change type\n",
    "X_train      = X_train.astype('float32')\n",
    "X_test       = X_test.astype('float32')\n",
    "\n",
    "# normalization\n",
    "X_train_mean = np.mean(X_train)\n",
    "X_train_std  = np.std(X_train)\n",
    "X_train      = (X_train - X_train_mean) / (X_train_std + eps)\n",
    "X_test       = (X_test  - X_train_mean) / (X_train_std + eps)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "class_num    = np.max(y_train) + 1 # consider class 0 \n",
    "y_train      = keras.utils.to_categorical(y_train, class_num).astype('float32')\n",
    "y_test       = keras.utils.to_categorical(y_test,  class_num).astype('float32')\n",
    "\n",
    "print('np.shape(X_train) = (%d, %d)' % np.shape(X_train))\n",
    "print('np.shape(y_train) = (%d, %d)' % np.shape(y_train))\n",
    "print('np.shape(X_test)  = (%d, %d)' % np.shape(X_test))\n",
    "print('np.shape(y_test)  = (%d, %d)' % np.shape(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter for training\n",
    "initial_learning_rate = 2.0\n",
    "decay_learning_rate   = 0.999\n",
    "epoch_num             = 50\n",
    "mini_batch_size       = (128 * 4)\n",
    "mini_batch_iter       = 30 # if None then all train data use　on a epoch\n",
    "random_seed           = 0\n",
    "dropconnect_ratio     = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix mini batch iteration num\n",
    "train_data_num   = len(y_train)\n",
    "if (mini_batch_iter is None):\n",
    "    mini_batch_iter = round((train_data_num / mini_batch_size) - 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "\n",
    "sess            = tf.InteractiveSession()\n",
    "\n",
    "# make model by tensorflow\n",
    "\n",
    "# input layer\n",
    "x               = tf.placeholder(dtype=tf.float32, shape=[None, 784])\n",
    "\n",
    "# multiply weight\n",
    "weight_1        = tf.Variable(initial_value=tf.random_normal(shape=[784, 100], \n",
    "                                                             mean=0.0, stddev=0.01))\n",
    "bias_1          = tf.Variable(initial_value=tf.zeros(shape=[100]))\n",
    "\n",
    "# drop connect\n",
    "weight_mask_1   = tf.Variable(tf.zeros(shape=[784, 100]), trainable=False)\n",
    "droped_weight_1 = weight_1 * weight_mask_1\n",
    "\n",
    "# \n",
    "matmul_1        = tf.matmul(a=x, b=droped_weight_1) + bias_1\n",
    "\n",
    "# activation\n",
    "activated_1     = tf.nn.relu(features=matmul_1)\n",
    "\n",
    "# multiply weight\n",
    "weight_2        = tf.Variable(initial_value=tf.random_normal(shape=[100, 10], \n",
    "                                                             mean=0.0, stddev=0.01))\n",
    "bias_2          = tf.Variable(initial_value=tf.zeros([10]))\n",
    "\n",
    "# drop connect\n",
    "weight_mask_2   = tf.Variable(initial_value=tf.zeros([100, 10]), trainable=False)\n",
    "droped_weight_2 = weight_2 * weight_mask_2\n",
    "\n",
    "# \n",
    "matmul_2        = tf.matmul(a=activated_1, b=droped_weight_2) + bias_2\n",
    "\n",
    "# output layer\n",
    "y               = tf.nn.softmax(logits=matmul_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "y_            = tf.placeholder(dtype=tf.float32, shape=[None, 10])\n",
    "prediction    = tf.clip_by_value(t=y, clip_value_min=eps, clip_value_max=1.0)\n",
    "loss          = - tf.reduce_mean( input_tensor=(y_ * tf.log(prediction)) )\n",
    "\n",
    "global_step   = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=initial_learning_rate,\n",
    "                                           global_step=global_step,\n",
    "                                           decay_steps=mini_batch_iter,\n",
    "                                           decay_rate=decay_learning_rate)\n",
    "\n",
    "optimizer     = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_step    = optimizer.minimize(loss=loss)\n",
    "\n",
    "tf.global_variables_initializer().run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "train_acc_stock  = np.zeros(epoch_num)\n",
    "test_acc_stock   = np.zeros(epoch_num)\n",
    "test_acc_best    = 0.0\n",
    "train_loss_stock = np.zeros(epoch_num)\n",
    "test_loss_stock  = np.zeros(epoch_num)\n",
    "\n",
    "fig              = plt.figure(figsize=(12,15),dpi=100)\n",
    "draw_pitch       = 5\n",
    "\n",
    "# training\n",
    "for epoch_i in range(epoch_num):\n",
    "    \n",
    "    # make index for mini batch selection\n",
    "    rand_idx    = np.random.permutation(len(y_train))\n",
    "    \n",
    "    # mini batch iteration (attentive　SGD)\n",
    "    for iter_i in range(mini_batch_iter):\n",
    "        \n",
    "        # set mini batch data\n",
    "        X_train_mini_batch = X_train[rand_idx[:mini_batch_size], :]\n",
    "        y_train_mini_batch = y_train[rand_idx[:mini_batch_size], :]\n",
    "        rand_idx           = rand_idx[mini_batch_size:]\n",
    "        \n",
    "        # drop connect\n",
    "        weight_mask_1_tmp  = sess.run(weight_mask_1)\n",
    "        weight_mask_1_tmp  = (np.random.uniform(0.0, 1.0, np.shape(weight_mask_1_tmp)) > dropconnect_ratio).astype('float32')\n",
    "        weight_mask_1.load(weight_mask_1_tmp, sess)\n",
    "\n",
    "        weight_mask_2_tmp  = sess.run(weight_mask_2)\n",
    "        weight_mask_2_tmp  = (np.random.uniform(0.0, 1.0, np.shape(weight_mask_2_tmp)) > dropconnect_ratio).astype('float32')\n",
    "        weight_mask_2.load(weight_mask_2_tmp, sess)\n",
    "        \n",
    "        # learning\n",
    "        train_step.run(feed_dict={x: X_train_mini_batch, y_: y_train_mini_batch})\n",
    "        \n",
    "    # validaiton\n",
    "    correct_prediction        = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    calc_acc                  = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    train_acc_stock[epoch_i]  = calc_acc.eval(feed_dict={x: X_train, y_: y_train})\n",
    "    test_acc_stock[epoch_i]   = calc_acc.eval(feed_dict={x: X_test,  y_: y_test})\n",
    "    train_loss_stock[epoch_i] = sess.run(fetches=loss, feed_dict={x: X_train, y_: y_train})\n",
    "    test_loss_stock[epoch_i]  = sess.run(fetches=loss, feed_dict={x: X_test,  y_: y_test})\n",
    "    \n",
    "    # best record update\n",
    "    if (test_acc_best < test_acc_stock[epoch_i]):\n",
    "        test_acc_best = test_acc_stock[epoch_i]\n",
    "    \n",
    "    if (((epoch_i + 1) % draw_pitch) == 0):\n",
    "        \n",
    "        # get now state\n",
    "        weight_1_tmp      = sess.run(weight_1)\n",
    "        weight_1_tmp      = np.sort(weight_1_tmp.flat[:])\n",
    "        weight_mask_1_tmp = sess.run(weight_mask_1)\n",
    "        weight_2_tmp      = sess.run(weight_2)\n",
    "        weight_2_tmp      = np.sort(weight_2_tmp.flat[:])\n",
    "        weight_mask_2_tmp = sess.run(weight_mask_2)\n",
    "\n",
    "        # draw\n",
    "        ax_331 = fig.add_subplot(3, 3, 1)\n",
    "        ax_331.cla()\n",
    "        clear_output(wait=True)\n",
    "        ax_331.grid(which='major',color=[0.7, 0.7, 0.7],linestyle='-')\n",
    "        ax_331.imshow(weight_mask_1_tmp, vmin=0, vmax=1, aspect='auto')\n",
    "        # plt.colorbar()\n",
    "        plt.title('mask state of 1st layer\\n(yellow is stay, navy is drop)')\n",
    "        display(fig)\n",
    "\n",
    "        ax_332 = fig.add_subplot(3, 3, 2)\n",
    "        ax_332.cla()\n",
    "        clear_output(wait=True)\n",
    "        ax_332.grid(which='major',color=[0.7, 0.7, 0.7],linestyle='-')\n",
    "        ax_332.plot(weight_1_tmp)\n",
    "        plt.title('plot weight of 1st layer\\n(sorted by value)')\n",
    "        display(fig)\n",
    "\n",
    "        ax_333 = fig.add_subplot(3, 3, 3)\n",
    "        ax_333.cla()\n",
    "        clear_output(wait=True)\n",
    "        ax_333.grid(which='major',color=[0.7, 0.7, 0.7],linestyle='-')\n",
    "        ax_333.hist(weight_1_tmp, bins=50)\n",
    "        plt.yscale('log')\n",
    "        plt.title('histogram weight of 1st layer\\n(std : %.3f)' % np.std(weight_1_tmp))\n",
    "        display(fig)\n",
    "\n",
    "        ax_334 = fig.add_subplot(3, 3, 4)\n",
    "        ax_334.cla()\n",
    "        clear_output(wait=True)\n",
    "        ax_334.grid(which='major',color=[0.7, 0.7, 0.7],linestyle='-')\n",
    "        ax_334.imshow(weight_mask_2_tmp, vmin=0, vmax=1, aspect='auto')\n",
    "        # plt.colorbar()\n",
    "        plt.title('mask state of 2nd layer\\n(yellow is stay, navy is drop)')\n",
    "        display(fig)\n",
    "\n",
    "        ax_335 = fig.add_subplot(3, 3, 5)\n",
    "        ax_335.cla()\n",
    "        clear_output(wait=True)\n",
    "        ax_335.grid(which='major',color=[0.7, 0.7, 0.7],linestyle='-')\n",
    "        ax_335.plot(weight_2_tmp)\n",
    "        plt.title('plot weight of 2nd layer\\n(sorted by value)')\n",
    "        display(fig)\n",
    "\n",
    "        ax_336 = fig.add_subplot(3, 3, 6)\n",
    "        ax_336.cla()\n",
    "        clear_output(wait=True)\n",
    "        ax_336.grid(which='major',color=[0.7, 0.7, 0.7],linestyle='-')\n",
    "        ax_336.hist(weight_2_tmp, bins=50)\n",
    "        plt.yscale('log')\n",
    "        plt.title('histogram weight of 2nd layer\\n(std : %.3f)' % np.std(weight_2_tmp))\n",
    "        display(fig)\n",
    "\n",
    "        ax_325 = fig.add_subplot(3, 2, 5)\n",
    "        ax_325.cla()\n",
    "        clear_output(wait=True)\n",
    "        ax_325.grid(which='major',color=[0.7, 0.7, 0.7],linestyle='-')\n",
    "        ax_325.plot(train_acc_stock[:(epoch_i + 1)])\n",
    "        ax_325.plot(test_acc_stock[:(epoch_i + 1)])\n",
    "        plt.ylim(-0.05, 1.05)\n",
    "        plt.title('accuracy of train data = %.2f%%\\naccuracy of test data = %.2f%% (best : %.2f%%)' % ((train_acc_stock[epoch_i] * 100), (test_acc_stock[epoch_i] * 100), (test_acc_best * 100)))\n",
    "        display(fig)\n",
    "\n",
    "        ax_326 = fig.add_subplot(3, 2, 6)\n",
    "        ax_326.cla()\n",
    "        clear_output(wait=True)\n",
    "        ax_326.grid(which='major',color=[0.7, 0.7, 0.7],linestyle='-')\n",
    "        ax_326.plot(train_loss_stock[:(epoch_i + 1)])\n",
    "        ax_326.plot(test_loss_stock[:(epoch_i + 1)])\n",
    "        plt.ylim(-0.05, 1.05)\n",
    "        plt.title('loss of train data = %.5f\\nloss of test data = %.5f' % (train_loss_stock[epoch_i], test_loss_stock[epoch_i]))\n",
    "        display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
